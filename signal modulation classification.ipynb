{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modulation_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNYr1At6z_QP"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer as LB\n",
        "from sklearn.preprocessing import normalize \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.layers.convolutional import Conv2D, ZeroPadding2D\n",
        "from keras.layers.core import Reshape, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense , BatchNormalization, Activation\n",
        "from keras import metrics\n",
        "\n",
        "from pandas import DataFrame as df\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import tarfile\n",
        "import pickle\n",
        "import random\n",
        "import keras\n",
        "import sys\n",
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifS74-IPkGZi"
      },
      "source": [
        "Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wEh_j9A-36T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3917b2a-8ec8-4c2f-83d5-868fb814d974"
      },
      "source": [
        "!wget http://opendata.deepsig.io/datasets/2016.10/RML2016.10b.tar.bz2\n",
        "!tar jxf RML2016.10b.tar.bz2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-14 13:38:54--  http://opendata.deepsig.io/datasets/2016.10/RML2016.10b.tar.bz2\n",
            "Resolving opendata.deepsig.io (opendata.deepsig.io)... 52.14.91.165\n",
            "Connecting to opendata.deepsig.io (opendata.deepsig.io)|52.14.91.165|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1245608913 (1.2G) [application/x-bzip2]\n",
            "Saving to: ‘RML2016.10b.tar.bz2’\n",
            "\n",
            "RML2016.10b.tar.bz2 100%[===================>]   1.16G  15.2MB/s    in 1m 49s  \n",
            "\n",
            "2021-01-14 13:40:43 (10.9 MB/s) - ‘RML2016.10b.tar.bz2’ saved [1245608913/1245608913]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAUjInDf0M4c"
      },
      "source": [
        "file = open(\"RML2016.10b.dat\",'rb')\n",
        "Xd = pickle.load(file, encoding = 'bytes')\n",
        "snrs, mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
        "X = [] \n",
        "lbl = []\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        X.append(Xd[(mod,snr)])\n",
        "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
        "X = np.vstack(X)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q3EMKoJ-4v6"
      },
      "source": [
        "## Create Features Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JygL40Bo_iNV"
      },
      "source": [
        "features = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0hE1Y_PP-QQ"
      },
      "source": [
        "features['raw'] = X[:,0], X[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiGPAY7s_OOe"
      },
      "source": [
        "features['derivative'] = normalize(np.gradient(X[:,0], axis = 1)), normalize(np.gradient(X[:,1], axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jc15J5r_OfX"
      },
      "source": [
        "features['integral'] = normalize(np.cumsum(X[:,0], axis = 1)), normalize(np.cumsum(X[:,1], axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvGETT-I_jAQ"
      },
      "source": [
        "**All Togetheer Feature Space**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDuvdmZo4CDR"
      },
      "source": [
        "def extract_features(*arguments):\n",
        "    \n",
        "    desired = ()            \n",
        "    for arg in arguments:\n",
        "        desired += features[arg]\n",
        "    \n",
        "    return np.stack(desired, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfnBc-rxCyQZ"
      },
      "source": [
        "## Train and Test Data Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYkv4lQuDR2F"
      },
      "source": [
        "data = extract_features('raw')\n",
        "labels = np.array(lbl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-oc9F5TKs4-"
      },
      "source": [
        "in_shape = data[0].shape\n",
        "out_shape = tuple([1]) + in_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_55-QcyklyDE",
        "outputId": "951a6b31-9428-45a6-ac5a-d5c30070ef78"
      },
      "source": [
        "in_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtUPPE4KKs45"
      },
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "n_examples = labels.shape[0]\n",
        "\n",
        "r = np.random.choice(range(n_examples), n_examples, replace = False)\n",
        "\n",
        "train_examples = r[:n_examples//2]\n",
        "test_examples =  r[n_examples//2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-gyBJhwKs47"
      },
      "source": [
        "X_train = data[train_examples]\n",
        "X_test = data[test_examples]\n",
        "\n",
        "y_train = LB().fit_transform(labels[train_examples][:,0])\n",
        "y_test = LB().fit_transform(labels[test_examples][:,0])\n",
        "\n",
        "snr_train = labels[train_examples][:,1].astype(int)\n",
        "snr_test = labels[test_examples][:,1].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7WC0d9sDyg-"
      },
      "source": [
        "## ABRO Model for Convolution Connected Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA2WXdzDS52C"
      },
      "source": [
        "from keras import backend as K\r\n",
        "\r\n",
        "def recall_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    return recall\r\n",
        "\r\n",
        "def precision_m(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    return precision\r\n",
        "\r\n",
        "def f1_m(y_true, y_pred):\r\n",
        "    precision = precision_m(y_true, y_pred)\r\n",
        "    recall = recall_m(y_true, y_pred)\r\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y8zIXRfZEX2"
      },
      "source": [
        "def modelCNN(btch_norm = False):\n",
        "  dr = 0.5\n",
        "  model = Sequential()\n",
        "  model.add(Reshape(out_shape, input_shape = in_shape))\n",
        "  model.add(ZeroPadding2D((0, 2), data_format = 'channels_first'))\n",
        "  model.add(Conv2D(256, (1, 3), padding = 'valid', name=\"conv1\", kernel_initializer='glorot_uniform', data_format=\"channels_first\"))\n",
        "\n",
        "  if (btch_norm):\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(dr))\n",
        "  model.add(ZeroPadding2D((0,2), data_format = 'channels_first'))\n",
        "  model.add(Conv2D(80, (2, 3), activation=\"relu\", name=\"conv3\", padding=\"valid\", kernel_initializer=\"glorot_uniform\", data_format=\"channels_first\"))\n",
        "\n",
        "  if (btch_norm):\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(dr))\n",
        "  model.add(Flatten())   \n",
        "  model.add(Dense(256, activation=\"relu\", name=\"dense1\", kernel_initializer=\"he_normal\"))\n",
        "\n",
        "  if (btch_norm):\n",
        "    model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "  model.add(Dropout(dr))\n",
        "  model.add(Dense(10, name=\"dense3\", kernel_initializer=\"he_normal\", activation = 'softmax'))\n",
        "  model.add(Reshape([len(mods)]))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJnFGjvG8CS2"
      },
      "source": [
        "model = modelCNN()\r\n",
        "history = model.fit(X_train, y_train, epochs = 80, batch_size = 1024, validation_split = 0.05, callbacks=[EarlyStopping(patience = 15, restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kDmW-VZIjHY"
      },
      "source": [
        "model.save(\"cnn.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCe_8hvuRTQI"
      },
      "source": [
        "model_batch = modelCNN(True)\r\n",
        "history_batch = model_batch.fit(X_train, y_train, epochs = 80, batch_size = 1024, validation_split = 0.05, callbacks=[EarlyStopping(patience = 15, restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCboPj6HmePv"
      },
      "source": [
        "model_batch.save(\"cnn_batch.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1HLIWliWXFI"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVeWbsoh8d8T"
      },
      "source": [
        "y_pred_cnn = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXFhiqicJaIv"
      },
      "source": [
        "y_pred_cnn_batch = model_batch.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTz4-uiUg-AK"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\r\n",
        "sns.heatmap(cm, annot=True, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEMnbBmTi53o"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\r\n",
        "sns.heatmap(cm_batch, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndyvvhaJk0IU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}